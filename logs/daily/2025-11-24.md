# Research Log: 2025-11-24

## Today's Goal
> Test new delay pattern (012345678 to match MusicGen) and assess model's ability to learn melody vs bass/drums

---

## Experiments

### EXP: `20251124_dia_001_bugfixes`
**Time:** 3:00am  
**Status:** ðŸŸ¢ Complete  
**Changes:** Asked LLMs to identify pressing bugs, found some low cost bugs  
**Result:** Updated and pushed to GitHub

---

### EXP: `20251124_dia_002_delay_pattern`
**Time:** 3:40am  
**Status:** ðŸŸ¢ Complete  
**Hypothesis:** Updating delay pattern to match MusicGen (012345678) will improve ability to learn melody. Before, codebook 0 was emphasized due to next codebooks being generated much later in sequence - good for bass/drums but not melody.  
**Changes:** Updated delay pattern, updated scripts to train from scratch with new pattern  
**Result:** Have to train from scratch now

---

### EXP: `20251124_dia_003_overfit_test1`
**Time:** 10:19pm  
**Status:** ðŸŸ¢ Complete  
**Hypothesis:** Basic overfit test on 1 sample  

**Results:**
- Basically random noise almost entire time
- Step 949: ~1/4 through 7sec sample started rendering perfect quality output. Other demo at same timestep was just noise
- Step 1099: Same pattern - 1/4 noise, 3/4 sample
- Steps 1199, 1299, 1399: Same pattern continued
- Pattern: Switched between pure noise OR 1/4 noise + 3/4 sample. Never gradual.

---

### EXP: `20251124_dia_004_overfit_test2`
**Status:** ðŸŸ¢ Complete  
**Changes:** Updated demos to CFG=1, prompt to match sample exactly  
**Hypothesis:** Should improve results  

**Results:**
- Got WORSE - pure noise up to 1699 steps despite similar training curves
- Step 1749: first 1/4 pure noise, last 3/4 was sample
- Pure noise until 2199: full sample
- Step 2249: pure noise
- Step 2299: mostly sample

---

### EXP: `20251124_dia_005_overfit_test3`
**Status:** ðŸŸ¢ Complete  
**Changes:** Took out random window  
**Result:** Performed exact same as before

---

### EXP: `20251124_dia_006_overfit_test4_unconditional`
**Time:** 11:31pm  
**Status:** ðŸŸ¢ Complete  
**Hypothesis:** Testing whether overfitting with unconditional_train=1 fixes the noise problem. If it does, might be encoder issue.  
**Config:** `unconditional_frac=1, batch=1, lr=1e-4, warmup=0`

```bash
python -m dia.finetune_acc --config ./dia/config_overfit.json --scratch \
  --output_dir /nfs/turbo/smtd-hwdong/ocamp/DONT_DELETE/new_delay_overfit \
  --preencoded_dir /home/ocamp/dia-new-delay/1sampledata/test1/preprocessedsingle \
  --batch_size 1 --grad_accum_steps 1 --unconditional_frac 1 \
  --eval_every_epochs 10 --demo_every_epochs 50 --epochs 10000 \
  --run_name new_delay_overfit --save_every 100 --learning_rate 1e-4 \
  --warmup_steps 0 --save_after_epoch 500 --force_single_gpu
```

**Results:**
- First music at step 2049 (seed 43), step 2099 (seed 42) - perfect original sample
- Similar results to previous â†’ NOT an encoder problem

---

### EXP: `20251124_dia_007_overfit_test4_temp0`
**Status:** ðŸŸ¢ Complete  
**Changes:** Eval demos with temperature=0, still unconditional  

**Results:**
- Step 249: Started hearing music with some noise at beginning
- Step 399: Both seeds rendering perfect samples, no noise, consistent

**Theory:** The model is simultaneously learning embeddings. Since we start from scratch, all embeddings are randomized. But since we're just overfitting on one sample, most embeddings are unchanged - we're overfitting just a subset. When we do higher temperature, it selects some random embeddings and outputs noise.

- Model wouldn't bounce between sample and noise - it was either all sample or all noise until first sample token hit, then all sample
- Once 1 sample token selected, model likely selects only sample tokens after (probabilities greatly outweigh random ones)
- Before with high temp: model randomly selecting between many tokens â†’ low likelihood of selecting first sample token
- Now with low temp: much more deterministic

**Next Steps:**
- Need to fill up the embedding space by increasing dataset and training longer
- Start with ~40 samples, unconditional first then conditional
- Keep demos at temp=0 and add temp=0.5 and temp=1 to test embedding learning over time
- Added: vocabulary coverage tracking, output entropy logging, multi-temperature demos

---

### EXP: `20251124_dia_008_40suey_unconditional`
**Status:** ðŸŸ¢ Complete  
**Config:** `batch=1, unconditional_frac=1, lr=1e-4`  
**Dataset:** 40 Suey Loop Kit samples (472,320 tokens, 1024/1024 vocab coverage)

```bash
python -m dia.finetune_acc --config ./dia/config_overfit.json --scratch \
  --output_dir /nfs/turbo/smtd-hwdong/ocamp/DONT_DELETE/new_delay_overfit \
  --preencoded_dir /home/ocamp/dia-new-delay/1sampledata/test1/preprocessed \
  --batch_size 1 --grad_accum_steps 1 --unconditional_frac 1 \
  --eval_every_epochs 10 --demo_every_epochs 50 --epochs 10000 \
  --run_name new_delay_overfit --save_every 100 --learning_rate 1e-4 \
  --warmup_steps 0 --save_after_epoch 500 --force_single_gpu
```

**Results by Epoch:**

| Epoch | temp=0 | temp=0.5 | temp=1 | Loss | Eval Loss | Entropy | Notes |
|-------|--------|----------|--------|------|-----------|---------|-------|
| 50 | buzzing (non-noise!) | noise | noise | - | increasing | decreasing | flag: not sure why temp=0 different |
| 100 | buzzing changed | less noise | less noise | - | 6.69 | decreasing | |
| 150 | <1sec, barely noise | muffled | muffled/<1sec | - | increasing faster | decreasing | |
| 200 | muffling | muffling | muffling | - | increasing | decreasing | grad clipping at 5 consistent |
| 250 | muffling (quieter) | muffling | muffling | ~1.3 avg | same | same | slight decrease in clipping |
| 300 | noise | noise | noise | ~0.77, down to 0.03-0.15 | ~9.5 | <0 (from >6 peak) | |
| 350 | noise | noise | noise | ~0.4 avg, ~0.1 actual | - | ~0.4 | |
| 400 | noise | noise | noise | ~0.03 | >11 | - | less grad clipping |

---

### EXP: `20251124_dia_009_40suey_conditional_0.15`
**Status:** ðŸ”´ Failed  
**Config:** `batch=1, unconditional_frac=0.15, lr=1e-4`

**Results by Epoch:**

| Epoch | temp=0 | temp=0.5 | temp=1 | Eval Loss | Notes |
|-------|--------|----------|--------|-----------|-------|
| 50 | click fade to silence | similar | noise | 6.7â†’6.6 | grad norm not clipping |
| 100 | buzzing noise | quieter noise | quieter noise | 6.69 | grad norm increasing |
| 150 | slightly more interesting buzzing | noise | noise | 6.73 | clipping at 5 consistent |
| 200 | buzzing fading | - | - | 7.55 | |

**Theory:** Batch size might be introducing too much variance

---

### EXP: `20251124_dia_010_40suey_unconditional_batch20`
**Status:** ðŸ”´ Failed  
**Config:** `batch=20, unconditional_frac=1, lr=1e-4`

```bash
python -m dia.finetune_acc --config ./dia/config_overfit.json --scratch \
  --output_dir /nfs/turbo/smtd-hwdong/ocamp/DONT_DELETE/new_delay_overfit \
  --preencoded_dir /home/ocamp/dia-new-delay/1sampledata/test1/preprocessed \
  --batch_size 20 --grad_accum_steps 1 --unconditional_frac 1 \
  --eval_step 20 --demo_every 100 --epochs 10000 \
  --run_name new_delay_overfit --save_every 100 --learning_rate 1e-4 \
  --warmup_steps 0 --save_after_epoch 500
```

**Results:**
| Epoch | Eval Loss | Notes |
|-------|-----------|-------|
| 100 | 6.75â†’6.6 | much smoother loss, max gradient 0.5, noisy samples |
| 200 | 6.76 | |
| 300 | 7 | pure noise |
| 400 | 7.4 | pure noise |

---

### EXP: `20251124_dia_011_40suey_conditional_batch20`
**Status:** ðŸ”´ Failed  
**Config:** `batch=20, unconditional_frac=0, lr=1e-4`
**W&B:** https://wandb.ai/ocamp-university-of-michigan/dia-music-finetuning/runs/j9nl1at8

```bash
python -m dia.finetune_acc --config ./dia/config_overfit.json --scratch \
  --output_dir /nfs/turbo/smtd-hwdong/ocamp/DONT_DELETE/new_delay_overfit \
  --preencoded_dir /home/ocamp/dia-new-delay/1sampledata/test1/preprocessed \
  --batch_size 20 --grad_accum_steps 1 --unconditional_frac 0 \
  --eval_step 20 --demo_every 100 --epochs 10000 \
  --run_name new_delay_overfit --save_every 100 --learning_rate 1e-4 \
  --warmup_steps 0 --save_after_epoch 500
```

**Results:**
- Epoch 100: eval 6.75â†’6.67, smooth train loss, temp=0 quiet buzzing, rest quiet noise
- Started with same exact pattern as before â†’ killed it

**Conclusion:** Eval loss is irrelevant! Was paying too close attention to that (facepalm)

**Theory:** Just not running it long enough

**Final Run:** 50 minutes, loss converged to 0.02, demos still just noise

---

### EXP: `20251124_dia_012_removing_tags_fixing_cfg`
**Status:** ðŸ”´ Failed  
**W&B:** https://wandb.ai/ocamp-university-of-michigan/dia-music-finetuning/runs/ycenomr9  
**Hypothesis:** With unconditional_frac at 0 but cfg at 4 for eval demos, it was still incorporating unconditional weights which messes up demos since unconditional learning was essentially still random. Also adding --tag_no_shuffle to simplify training and reduce generalization.

```bash
python -m dia.finetune_acc \
  --config ./dia/config_overfit.json --scratch \
  --output_dir /nfs/turbo/smtd-hwdong/ocamp/DONT_DELETE/new_delay_overfit \
  --preencoded_dir /home/ocamp/dia-new-delay/1sampledata/test1/preprocessed \
  --batch_size 20 --grad_accum_steps 1 --unconditional_frac 0 \
  --eval_step 20 --demo_every 100 --epochs 10000 \
  --run_name new_delay_overfit --save_every 100 --learning_rate 1e-4 \
  --warmup_steps 0 --save_after_epoch 500 --tag_no_shuffle
```

**Results:**
- Epoch 100: very smooth train/loss
- Very unsuccessful

**Theory:** Must be some dataset or collate issue. As soon as I changed the collate/dataset from the sliding window code, it broke.

---

### EXP: `20251124_dia_013_removing_special_tokens_from_loss`
**Status:** ðŸ”´ Failed  
**Changes:** Removed special tokens from loss calculation  
**Result:** Had no relevant change from previous - root issue still failing

---

### EXP: `20251124_dia_014_reverted_dataset_collate`
**Status:** ðŸŸ¢ Complete - BREAKTHROUGH  
**W&B:** https://wandb.ai/ocamp-university-of-michigan/dia-music-finetuning/runs/e8bcybi2  
**Runtime:** 6h 51m 42s (overnight)  
**Config:** `configs/experiments/20251124_dia_003.json`

**Results:**
- Gradients rarely ever clipped
- Steady increase log-type graph reaching max around 30k steps
- Eval decreased until ~8000 steps then increased consistently until training stopped at 10000 epochs (ended ~9.3)
- Train/loss finished around 3.5, consistently decreased entire time
- Output entropy consistently decreased
- Audio files clearly sound like training data âœ…

**Why it worked:**
1. The code update bringing back the old sliding window implementation fixed it
2. Previous dataset where it would learn the same 40 samples was way too small
3. Overfitting on 1 sample was likely outlier case - can just change all params to optimize for same token sequence
4. With small dataset, gradients are too big causing grad norm to skyrocket â†’ lose important gradients due to clipping â†’ don't actually learn anything

**The Fix (sliding window logic was inverted):**

Old (broken) logic:
- `use_sliding_window=True`: return full sequence, let collate_fn do random cropping
- `use_sliding_window=False`: fixed crop from start (deterministic)

New (working) logic:
- `use_sliding_window=True`: random crop in Dataset (data augmentation, efficient)
- `use_sliding_window=False`: fixed crop from start (deterministic)

**Reminder TODO:** Confirm loss function that excludes special tokens since we added that and later took it out.

---

## Key Insights
- Temperature=0 is critical for assessing model learning when training from scratch (random embeddings)
- Model learns embeddings subset during overfit - higher temp samples from random unlearned embeddings â†’ noise
- Once first "learned" token selected, model stays on track (probabilities dominate)
- Eval loss is NOT a good indicator of generation quality during from-scratch training
- Need to fill embedding space with more data and longer training
- Sliding window logic inversion was causing deterministic cropping (always first ~10 sec) â†’ artificially low loss

## Blockers / Questions
- Why does temp=0 show different behavior so early while temp=0.5/1 show noise?
- Is 40 samples enough to fill embedding space?

## Tomorrow's Plan
- Run longer training overnight
- Consider larger dataset
- Monitor vocabulary coverage as training progresses

---

## Commits

