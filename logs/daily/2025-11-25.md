# Research Log: 2025-11-25

## Overview
Tested delay pattern ablation - MusicGen-style sequential delay vs original Dia pattern. MusicGen delay pattern validated as superior.

---

## Experiments

### Delay ablation test
**Hypothesis:** MusicGen-style delay pattern (0,1,2,3,4,5,6,7,8 repeated) will outperform original Dia pattern (0,8,9,10,11,12,13,14,15 repeated) for melody-focused data.

**Results @ ~22k steps:**

| Metric | MusicGen (NEW) | Dia (OLD) | Winner |
|--------|----------------|-----------|--------|
| Train loss | 4.24 | 4.41 | NEW (~4% lower) |
| Output entropy | 4.45 | 4.65 | NEW (more confident) |
| Eval loss | 7.91 | 7.72 | NEW overfitting harder (expected for memorization) |
| Variance | smoother/stable | noisier | NEW |
| Audio (ckpts 22499, 32499) | smoother, cleaner melody | - | NEW |

**Conclusion:** MusicGen delay pattern wins. Validates hypothesis that equal codebook weighting benefits high-frequency content. Aligns with MusicGen paper findings.

**Theory:** Closer together is better. Waiting too long to generate subsequent tokens is not good. Larger gaps force model to reconstruct from distant sequence positions degrading coherence - relevant context is further away, making it harder for model to remember rather than having fresh info.

---

### Delay compressed test
**W&B:** https://wandb.ai/ocamp-university-of-michigan/dia-music-finetuning/groups/delay_ablation_test/runs/h4d947hj  
**Theory:** Pushing the limits of sequential by compressing it to see how it reacts. Might not work as well but would be faster inference.

**Results:**
- Train/loss and entropy ended up slightly on par but slightly worse than original Dia delay from dia_004
- Cut it early since not improving and noticeable difference compared to musicgen delay
- Output entropy higher on average than Dia delay
- Train/loss usually higher on average than Dia delay
- Eval lower = doing worse on overfitting (which was the goal)
- Did overall perform better than 004 though. While entropy ended up being a bit less than dia entropy, the loss is now inbetween 003 and 004.

**Conclusion:** Sequential ordering matters. Closer != better - the unique sequential delay per codebook matters more than just minimizing max delay. Having too far proximity hurts, but so does too close proximity. Balance is just sequential proximity.

**Final verdict:** MusicGen delay pattern is the way to go for the foreseeable future.

**TODO:** Potentially test out new delay patterns

---

## Key Insights
- MusicGen-style delay outperforms both original Dia and compressed patterns
- Sequential proximity matters - not too far, not too close
- Equal codebook weighting benefits high-frequency content (melody)

---

## Commits
- `02:48` [`07eaf4c`] **main**: 20251124_dia_011: conditional batch20 - loss converged but demos still noise (6 files)
- `03:14` [`5c28760`] **main**: 20251124_dia_001: removing tags and fixing cfg (4 files)
- `03:44` [`e6b6b0b`] **main**: 20251124_dia_002_removing special tokens from loss calculation (7 files)
- `03:58` [`e2be505`] **main**: 20251124_dia_003_reverted somewhat back to old implementation of dataset/collate (5 files)
- `11:41` [`4c6f347`] **main**: 20251124_dia_003_reverted somewhat back to old implementation of dataset/collate (4 files)
- `16:34` [`3007875`] **main**: Eval script (6 files)
- `16:35` [`587e719`] **main**: Eval script (3 files)
- `16:35` [`382b663`] **main**: Eval script (2 files)
- `16:55` [`a70dcb0`] **main**: Updated logging (22 files)
- `17:01` [`6b4f2c9`] **main**: 20251125_dia_004_delay_ablation (7 files)
- `23:29` [`3608c94`] **main**: 20251125_dia_005_delay_compressed_model (21 files)
